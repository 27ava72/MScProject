{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import transform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import matplotlib.dates as mdates\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send request to NASA for the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iowa_bbox = [-96.639704, 40.375437, -90.140061, 43.501196]  \n",
    "\n",
    "def get_smapL4_data(min_lon, min_lat, max_lon, max_lat, session):\n",
    "    bounding_box = f\"{min_lon},{min_lat},{max_lon},{max_lat}\"\n",
    "    params = {\n",
    "        'short_name': 'SPL4SMGP',\n",
    "        'version': '007',\n",
    "        'temporal': '2021-06-30T00:00:00Z,2022-03-31T23:59:59Z',\n",
    "        'bounding_box': bounding_box,\n",
    "        'bbox': bounding_box,\n",
    "        'format': 'HDF-EOS5',\n",
    "        'projection': 'GEOGRAPHIC',\n",
    "        'page_size': 2000,\n",
    "        'request_mode': 'async',\n",
    "        'email': ''\n",
    "    }\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {token}'\n",
    "    }\n",
    "\n",
    "    site = 'https://n5eil02u.ecs.nsidc.org/egi/request?'\n",
    "    url = site + \"&\".join([f\"{key}={value}\" for key, value in params.items()])\n",
    "    response = session.get(url, headers=headers, timeout=30)\n",
    "    if response.status_code == 401:\n",
    "        response = session.get(response.url)\n",
    "    response.raise_for_status()\n",
    "    return response.content\n",
    "\n",
    "def get_data(min_lon, min_lat, max_lon, max_lat, session):\n",
    "    try:\n",
    "        data = get_smapL4_data(min_lon, min_lat, max_lon, max_lat, session)\n",
    "        if data:\n",
    "            print(\"Data has been requested\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered: {e}\")\n",
    "    return False\n",
    "\n",
    "token = \n",
    "iowa_min_lon, iowa_min_lat, iowa_max_lon, iowa_max_lat = iowa_bbox\n",
    "\n",
    "with requests.Session() as session:\n",
    "    get_data(iowa_min_lon, iowa_min_lat, iowa_max_lon, iowa_max_lat, session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open data file and extract relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ''\n",
    "all_data = []\n",
    "for dir, dirs, files in os.walk(root):\n",
    "    for file in files:\n",
    "        if file.endswith('.h5') or file.endswith('.he5'):  \n",
    "            file_path = os.path.join(dir, file)\n",
    "            try:\n",
    "                with h5py.File(file_path, mode='r') as f:\n",
    "                   \n",
    "                    if 'gph' in file:\n",
    "                        dataset_path = '/HDFEOS/GRIDS/Geophysical_Data/Data Fields/sm_surface'\n",
    "                    else:\n",
    "                        dataset_path = '/HDFEOS/GRIDS/Analysis_Data/Data Fields/sm_surface_analysis'\n",
    "                    \n",
    "           \n",
    "                    data = f[dataset_path][:]\n",
    "                    attrs = f[dataset_path].attrs\n",
    "                    _FillValue = attrs['_FillValue']\n",
    "                    valid_max = attrs['valid_max']\n",
    "                    valid_min = attrs['valid_min']\n",
    "                    invalid = np.logical_or(data > valid_max, data < valid_min)\n",
    "                    invalid = np.logical_or(invalid, data == _FillValue)\n",
    "                    data[invalid] = np.nan\n",
    "                    data = np.ma.masked_where(np.isnan(data), data)\n",
    "                    lat_path = '/HDFEOS/GRIDS/FileMainGroup/Data Fields/cell_lat'\n",
    "                    lon_path = '/HDFEOS/GRIDS/FileMainGroup/Data Fields/cell_lon'\n",
    "                    latitude = f[lat_path][:]\n",
    "                    longitude = f[lon_path][:]\n",
    "                    \n",
    "                    try:\n",
    "                        #print(f\"filename: {file}\")\n",
    "                        date_str = file.split('_')[4]\n",
    "                        #print(f\"date string: {date_str}\")\n",
    "                        date = pd.to_datetime(date_str, format='%Y%m%dT%H%M%S')\n",
    "                        #print(f\"date: {date}\")\n",
    "                    except (IndexError, ValueError) as date_error:\n",
    "                        print(f\"Date extraction failed for filename: {file}. Error: {date_error}\")\n",
    "                        date = None \n",
    "                    for lat, lon, sm in zip(latitude.flatten(), longitude.flatten(), data.flatten()):\n",
    "                        all_data.append({'date': date, 'latitude': lat, 'longitude': lon, 'soil_moisture': sm, 'file': file})\n",
    "\n",
    "\n",
    "            except OSError as e:\n",
    "                print(f\"problem opening file: {e}\")\n",
    "            except KeyError as e:\n",
    "                print(f\"not in file {file_path}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"problem processing file {file_path}: {e}\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "'''if 'date' in df.columns and not df['date'].isnull().all():\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "else:\n",
    "    print(\"'date' column invalid.\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go to QGIS and adapt the resolution accordingly and then return and extract data from the new csv file. In QGIS indexes were assigned based on whether a point (lat, lon) was within a grid cell. Then saves as a csv, so filtering by index means we can seperate by grid and therefore aggregate spatially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "df = pd.read_csv(path, parse_dates=['date'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df_agg = df[df['id'] == 1]\n",
    "end = pd.Timestamp('2023-06-07 23:59:59')\n",
    "start = end - pd.Timedelta(days=6)\n",
    "df_agg = df_agg[(df_agg['date'] >= start) & (df_agg['date'] <= end)]\n",
    "\n",
    "def aggregate(df):\n",
    "    aggregated = df.groupby(['date', 'latitude', 'longitude']).agg({\n",
    "        'soil_moisture': ['first', 'last', 'max', 'min', 'mean']\n",
    "    }).reset_index()\n",
    "    \n",
    "    aggregated.columns = ['date', 'latitude', 'longitude', 'open', 'close', 'max', 'min', 'mean']\n",
    "    \n",
    "    return aggregated\n",
    "def open_val_shift(df):\n",
    "    df['open'] = df['close'].shift(1)\n",
    "    df['open'].iloc[0] = mean_open  \n",
    "    return df\n",
    "\n",
    "\n",
    "aggregated = aggregate(df_agg)\n",
    "mean_open = aggregated['open'].mean()\n",
    "aggregated = aggregated.groupby(['latitude', 'longitude']).apply(open_val_shift).reset_index(drop=True)\n",
    "ans = aggregated.groupby('date').agg({\n",
    "    'open': 'mean',  # Mean of the open values\n",
    "    'close': 'mean',  # Mean of the close values\n",
    "    'max': 'max',     # Maximum of all max values\n",
    "    'min': 'min',     # Minimum of all min values\n",
    "    'mean': 'mean'    # Mean of all mean values\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "print(ans)\n",
    "\n",
    "def candlestick(df, title):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.index.name = 'Date'\n",
    "    df = df.rename(columns={'open': 'Open', 'close': 'Close', 'max': 'High', 'min': 'Low'})\n",
    "    mpf.plot(df, type='candle', style='charles', title=title, ylabel='Soil Moisture', volume=False)\n",
    "\n",
    "\n",
    "candlestick(ans, 'Candlestick Plot for SM at 27km Resolution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_moisture_stats = df['soil_moisture'].describe()\n",
    "print(\"Soil Moisture Statistics:\")\n",
    "print(soil_moisture_stats)\n",
    "\n",
    "dailySm = df['soil_moisture'].resample('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = {\n",
    "    'Northwest': {'lat_min': 42, 'lat_max': 44, 'lon_min': -96, 'lon_max': -94},\n",
    "    'Central': {'lat_min': 41, 'lat_max': 43, 'lon_min': -94, 'lon_max': -92},\n",
    "    'Southeast': {'lat_min': 40, 'lat_max': 42, 'lon_min': -92, 'lon_max': -90}\n",
    "}\n",
    "\n",
    "def regional(row):\n",
    "    for region, bounds in regions.items():\n",
    "        if bounds['lat_min'] <= row['latitude'] <= bounds['lat_max'] and bounds['lon_min'] <= row['longitude'] <= bounds['lon_max']:\n",
    "            return region\n",
    "    return 'Other'\n",
    "\n",
    "df['region'] = df.apply(regional, axis=1)\n",
    "df_filtered = df[df['region'] != 'Other']\n",
    "regions = (df_filtered.groupby(['region', pd.Grouper(key='date', freq='D')])['soil_moisture'].mean().reset_index()).pivot(index='date', columns='region', values='soil_moisture')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for region in regions.columns:\n",
    "    plt.plot(regions.index, regions[region], label=region)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volumetric Soil Moisture')\n",
    "plt.title('Soil Moisture Time Series Daily Resolution Aggregated by Region for June')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
